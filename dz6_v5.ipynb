{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW_IMrzboL_v"
      },
      "source": [
        "Задание 1.\n",
        "\n",
        "Обучите нейронную сеть решать шифр Цезаря.\n",
        "\n",
        "Что необходимо сделать:\n",
        "\n",
        "* Написать алгоритм шифра Цезаря для генерации выборки (сдвиг на К каждой буквы. Например, при сдвиге на 2 буква “А” переходит в букву “В” и тп)\n",
        "* Сделать нейронную сеть\n",
        "* Обучить ее (вход - зашифрованная фраза, выход - дешифрованная фраза)\n",
        "* Проверить качество\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "gYu83KWCoL_3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # для работы с данными\n",
        "import time  # для оценки времени\n",
        "import torch  # для написания нейросети\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abvgd = 'abcdefghijklmnopqrstuvwxyz '\n",
        "len(abvgd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "FlNxD3M6oL_4"
      },
      "outputs": [],
      "source": [
        "def f_cifer_cesar(phrase,num_K):\n",
        "\n",
        "    abvgd = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    if num_K>len(abvgd):\n",
        "        num_K=len(abvgd)\n",
        "\n",
        "    ab_ba=abvgd+abvgd[::-1]\n",
        "\n",
        "    w_i_dict = {w: i for i, w in enumerate(abvgd)}\n",
        "\n",
        "    loc_lst=''\n",
        "    for letter in phrase:\n",
        "        if letter in abvgd:\n",
        "            loc_lst+=ab_ba[w_i_dict[letter]+num_K]\n",
        "        else:\n",
        "            loc_lst+=letter\n",
        "\n",
        "    return loc_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "d6g6XE_yoL_5"
      },
      "outputs": [],
      "source": [
        "def f_clean_text(phrase):\n",
        "\n",
        "    abvgd = 'abcdefghijklmnopqrstuvwxyz '\n",
        "\n",
        "    w_i_dict = {w: i for i, w in enumerate(abvgd)}\n",
        "\n",
        "    loc_lst=''\n",
        "    for letter in phrase.lower():\n",
        "        if letter in abvgd:\n",
        "            loc_lst+=abvgd[w_i_dict[letter]]\n",
        "        else:\n",
        "            loc_lst+=''\n",
        "\n",
        "    return loc_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "xQ2vrL-ZoL_6"
      },
      "outputs": [],
      "source": [
        "def f_text_to_num(phrase):\n",
        "\n",
        "    abvgd = 'abcdefghijklmnopqrstuvwxyz '\n",
        "\n",
        "    w_i_dict = {w: i for i, w in enumerate(abvgd)}\n",
        "\n",
        "    loc_lst=[]\n",
        "    for letter in phrase.lower():\n",
        "        if letter in abvgd:\n",
        "            loc_lst.append(w_i_dict[letter])\n",
        "\n",
        "    return torch.Tensor(loc_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "siHXKn9ToL_6"
      },
      "outputs": [],
      "source": [
        "def f_num_to_text(lst):\n",
        "\n",
        "    abvgd = 'abcdefghijklmnopqrstuvwxyz '\n",
        "    lst=list(lst.detach().numpy())\n",
        "    i_w_dict = {i: w for i, w in enumerate(abvgd)}\n",
        "\n",
        "    loc_lst=''\n",
        "    for num in lst:\n",
        "        if num in range(len(abvgd)):\n",
        "            loc_lst+=i_w_dict[num]\n",
        "\n",
        "    return loc_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "cOaj5pizoL_9"
      },
      "outputs": [],
      "source": [
        "def f_cadr_text(phrase,lenght):\n",
        "\n",
        "    loc_lst=phrase[:50]\n",
        "    #for i in range(50):#range(lenght-len(phrase)):\n",
        "        #loc_lst+=' '\n",
        "\n",
        "    return loc_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81QliFL7oL_9",
        "outputId": "7aa7548f-8b91-492c-c4e1-160d086ab89c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10891 entries, 0 to 10890\n",
            "Data columns (total 1 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   normalized_text  10891 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 85.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data.csv',usecols=['normalized_text'])\n",
        "\n",
        "df=df.dropna().reset_index(drop=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "kb2vN7imoL_-"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>len_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
              "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
              "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ooh look maggie what is that do-dec-ah-edron d...</td>\n",
              "      <td>ooh look maggie what is that dodecahedron dode...</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thats okay bart nobody really believed it we w...</td>\n",
              "      <td>thats okay bart nobody really believed it we w...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bart my birthday is in two days im gonna be ei...</td>\n",
              "      <td>bart my birthday is in two days im gonna be ei...</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     normalized_text  \\\n",
              "0  im trying to teach maggie that nature doesnt e...   \n",
              "1  its like an ox only it has a hump and a dewlap...   \n",
              "2  ooh look maggie what is that do-dec-ah-edron d...   \n",
              "3  thats okay bart nobody really believed it we w...   \n",
              "4  bart my birthday is in two days im gonna be ei...   \n",
              "\n",
              "                                          clean_text  len_text  \n",
              "0  im trying to teach maggie that nature doesnt e...       122  \n",
              "1  its like an ox only it has a hump and a dewlap...        78  \n",
              "2  ooh look maggie what is that dodecahedron dode...        54  \n",
              "3  thats okay bart nobody really believed it we w...        74  \n",
              "4  bart my birthday is in two days im gonna be ei...        98  "
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['clean_text']=[f_clean_text(x) for x in df['normalized_text']]\n",
        "df['len_text']=[len(x) for x in df['clean_text']]\n",
        "df=df[df['len_text']>50].reset_index(drop=True)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "lenght_max=50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s8yqkJToL_-",
        "outputId": "40da2cba-38a2-4c70-9eb6-78c3838fb287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(f_cadr_text(df['clean_text'][0],lenght_max))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "EK3i_QIvoMAA"
      },
      "outputs": [],
      "source": [
        "df['cadr_text']=[f_cadr_text(x,lenght_max) for x in df['clean_text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "Q1ndZyAhoMAB"
      },
      "outputs": [],
      "source": [
        "K_cifer=25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "eGpeX7kyoMAE",
        "outputId": "710eb7bd-46fb-4dfa-fe9d-6d3c43b4c487"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>normalized_text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>len_text</th>\n",
              "      <th>cadr_text</th>\n",
              "      <th>cifer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
              "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
              "      <td>122</td>\n",
              "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
              "      <td>so hjcsnu hm hwzyt ozuusw htzh nzhgjw xmwinh w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
              "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
              "      <td>78</td>\n",
              "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
              "      <td>shi psqw zn md mnpc sh tzi z tgol znx z xwepzl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ooh look maggie what is that do-dec-ah-edron d...</td>\n",
              "      <td>ooh look maggie what is that dodecahedron dode...</td>\n",
              "      <td>54</td>\n",
              "      <td>ooh look maggie what is that dodecahedron dode...</td>\n",
              "      <td>mmt pmmq ozuusw etzh si htzh xmxwyztwxjmn xmxw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thats okay bart nobody really believed it we w...</td>\n",
              "      <td>thats okay bart nobody really believed it we w...</td>\n",
              "      <td>74</td>\n",
              "      <td>thats okay bart nobody really believed it we w...</td>\n",
              "      <td>htzhi mqzc zzjh nmzmxc jwzppc zwpswfwx sh ew e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bart my birthday is in two days im gonna be ei...</td>\n",
              "      <td>bart my birthday is in two days im gonna be ei...</td>\n",
              "      <td>98</td>\n",
              "      <td>bart my birthday is in two days im gonna be ei...</td>\n",
              "      <td>zzjh oc zsjhtxzc si sn hem xzci so umnnz zw ws...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     normalized_text  \\\n",
              "0  im trying to teach maggie that nature doesnt e...   \n",
              "1  its like an ox only it has a hump and a dewlap...   \n",
              "2  ooh look maggie what is that do-dec-ah-edron d...   \n",
              "3  thats okay bart nobody really believed it we w...   \n",
              "4  bart my birthday is in two days im gonna be ei...   \n",
              "\n",
              "                                          clean_text  len_text  \\\n",
              "0  im trying to teach maggie that nature doesnt e...       122   \n",
              "1  its like an ox only it has a hump and a dewlap...        78   \n",
              "2  ooh look maggie what is that dodecahedron dode...        54   \n",
              "3  thats okay bart nobody really believed it we w...        74   \n",
              "4  bart my birthday is in two days im gonna be ei...        98   \n",
              "\n",
              "                                           cadr_text  \\\n",
              "0  im trying to teach maggie that nature doesnt e...   \n",
              "1  its like an ox only it has a hump and a dewlap...   \n",
              "2  ooh look maggie what is that dodecahedron dode...   \n",
              "3  thats okay bart nobody really believed it we w...   \n",
              "4  bart my birthday is in two days im gonna be ei...   \n",
              "\n",
              "                                          cifer_text  \n",
              "0  so hjcsnu hm hwzyt ozuusw htzh nzhgjw xmwinh w...  \n",
              "1  shi psqw zn md mnpc sh tzi z tgol znx z xwepzl...  \n",
              "2  mmt pmmq ozuusw etzh si htzh xmxwyztwxjmn xmxw...  \n",
              "3  htzhi mqzc zzjh nmzmxc jwzppc zwpswfwx sh ew e...  \n",
              "4  zzjh oc zsjhtxzc si sn hem xzci so umnnz zw ws...  "
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['cifer_text']=[f_cifer_cesar(x,K_cifer) for x in df['cadr_text']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wu_aKM4ioMAF",
        "outputId": "c0ed7e0c-6786-4e05-a4d4-403b84c767db"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cadr_text</th>\n",
              "      <th>cifer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im trying to teach maggie that nature doesnt e...</td>\n",
              "      <td>so hjcsnu hm hwzyt ozuusw htzh nzhgjw xmwinh w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>its like an ox only it has a hump and a dewlap...</td>\n",
              "      <td>shi psqw zn md mnpc sh tzi z tgol znx z xwepzl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ooh look maggie what is that dodecahedron dode...</td>\n",
              "      <td>mmt pmmq ozuusw etzh si htzh xmxwyztwxjmn xmxw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thats okay bart nobody really believed it we w...</td>\n",
              "      <td>htzhi mqzc zzjh nmzmxc jwzppc zwpswfwx sh ew e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bart my birthday is in two days im gonna be ei...</td>\n",
              "      <td>zzjh oc zsjhtxzc si sn hem xzci so umnnz zw ws...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           cadr_text  \\\n",
              "0  im trying to teach maggie that nature doesnt e...   \n",
              "1  its like an ox only it has a hump and a dewlap...   \n",
              "2  ooh look maggie what is that dodecahedron dode...   \n",
              "3  thats okay bart nobody really believed it we w...   \n",
              "4  bart my birthday is in two days im gonna be ei...   \n",
              "\n",
              "                                          cifer_text  \n",
              "0  so hjcsnu hm hwzyt ozuusw htzh nzhgjw xmwinh w...  \n",
              "1  shi psqw zn md mnpc sh tzi z tgol znx z xwepzl...  \n",
              "2  mmt pmmq ozuusw etzh si htzh xmxwyztwxjmn xmxw...  \n",
              "3  htzhi mqzc zzjh nmzmxc jwzppc zwpswfwx sh ew e...  \n",
              "4  zzjh oc zsjhtxzc si sn hem xzci so umnnz zw ws...  "
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=df[['cadr_text','cifer_text']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "n81DM49RoMAG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-144-9731b690fcf2>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['cifer_vec']=[f_text_to_num(x) for x in df['cifer_text']]\n",
            "<ipython-input-144-9731b690fcf2>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['cadr_vec']=[f_text_to_num(x) for x in df['cadr_text']]\n"
          ]
        }
      ],
      "source": [
        "df['cifer_vec']=[f_text_to_num(x) for x in df['cifer_text']]\n",
        "df['cadr_vec']=[f_text_to_num(x) for x in df['cadr_text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "Wo3OHLQ3oMAG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import  train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cifer_text'], df['cadr_text'], test_size=0.2, random_state=42)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(df['cifer_vec'], df['cadr_vec'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "865H4IAZoMAH"
      },
      "outputs": [],
      "source": [
        "X_train=X_train.reset_index(drop=True)\n",
        "X_test=X_test.reset_index(drop=True)\n",
        "y_train=y_train.reset_index(drop=True)\n",
        "y_test=y_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "window_size=50\n",
        "def input_data(seq_x,seq_y,ws=window_size):\n",
        "    out = []\n",
        "    L = len(seq_x)\n",
        "    \n",
        "    for i in range(L):\n",
        "        window = seq_x[i]\n",
        "        label = seq_y[i]\n",
        "        out.append((window,label))\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_data = input_data(X_train,y_train,ws=window_size)\n",
        "test_data = input_data(X_test,y_test,ws=window_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "Wwlt7K16vavV"
      },
      "outputs": [],
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self,input_size = 27, hidden_size = 256, out_size = 27):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size)\n",
        "        self.linear = torch.nn.Linear(hidden_size,out_size)\n",
        "        self.hidden = (torch.zeros(1,1,hidden_size),torch.zeros(1,1,hidden_size))\n",
        "    \n",
        "    def forward(self,seq):\n",
        "        #lstm_out, self.hidden = self.lstm(seq.view(len(seq),1,-1), self.hidden)\n",
        "        lstm_out, self.hidden = self.lstm(seq.view(1,1,27), self.hidden)\n",
        "        pred = self.linear(lstm_out.view(256))\n",
        "        return pred#[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model = LSTM()\n",
        "criterion = torch.nn.MSELoss()#reduction='sum'\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler1 = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(27, 256)\n",
              "  (linear): Linear(in_features=256, out_features=27, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([27]) \n",
            " torch.Size([27]) \n",
            "\n",
            "27 \n",
            " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0.]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "abvgd = 'abcdefghijklmnopqrstuvwxyz '\n",
        "\n",
        "w_i_dict = {w: i for i, w in enumerate(abvgd)}\n",
        "\n",
        "vectors_letter=torch.eye(27,27)\n",
        "\n",
        "for x_seq, y_seq in train_data[:1][:]:\n",
        "    for x_seq_letter, y_seq_letter in zip(x_seq, y_seq):\n",
        "            \n",
        "            x_seq_letter=vectors_letter[w_i_dict[x_seq_letter]]\n",
        "            y_seq_letter=vectors_letter[w_i_dict[y_seq_letter]]\n",
        "            print(x_seq_letter.shape,'\\n',y_seq_letter.shape,'\\n')\n",
        "            print(len(x_seq_letter),'\\n',y_seq_letter,'\\n')\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "\n",
        "for i in range(epochs):\n",
        "    \n",
        "    for x_seq, y_seq in train_data[:30][:]:\n",
        "        for x_seq_letter, y_seq_letter in zip(x_seq, y_seq):\n",
        "            \n",
        "            x_seq_letter=vectors_letter[w_i_dict[x_seq_letter]]\n",
        "            y_seq_letter=vectors_letter[w_i_dict[y_seq_letter]]\n",
        "            #print(x_seq_letter,'\\n',y_seq_letter,'\\n')\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            model.hidden = (torch.zeros(1,1,model.hidden_size),\n",
        "                        torch.zeros(1,1,model.hidden_size))\n",
        "            \n",
        "            y_pred = model(x_seq_letter)\n",
        "            loss = criterion(y_pred.squeeze(), y_seq_letter.squeeze())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "    \n",
        "    scheduler1.step()\n",
        "    \n",
        "    for x_seq, y_seq in test_data[:10][:]:  \n",
        "        for x_seq_letter, y_seq_letter in zip(x_seq, y_seq):  \n",
        "\n",
        "            x_seq_letter=vectors_letter[w_i_dict[x_seq_letter]]\n",
        "            y_seq_letter=vectors_letter[w_i_dict[y_seq_letter]]\n",
        "\n",
        "            y_pred = model(x_seq_letter.squeeze())\n",
        "            \n",
        "            loss_test = criterion(y_pred.squeeze(), y_seq_letter.squeeze())\n",
        "            \n",
        "    if (i+1) % 1 == 0:\n",
        "        print(f\"Epoch {i+1} MSE_TRAIN_Loss: {loss.item()}\")\n",
        "        print(f\"          MSE_TEST__Loss: {loss_test}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 1.0\n",
            "Accuracy 0.99\n",
            "Accuracy 0.98\n",
            "Accuracy 0.985\n",
            "Accuracy 0.988\n"
          ]
        }
      ],
      "source": [
        "i=0\n",
        "Accuracy=0\n",
        "for x_seq, y_seq in test_data[:5][:]:  \n",
        "        \n",
        "        i+=1\n",
        "        for x_seq_letter, y_seq_letter in zip(x_seq, y_seq):  \n",
        "\n",
        "            x_seq_letter=vectors_letter[w_i_dict[x_seq_letter]]\n",
        "            y_seq_letter=vectors_letter[w_i_dict[y_seq_letter]]\n",
        "\n",
        "            y_pred = model(x_seq_letter)\n",
        "            \n",
        "            loss_test = criterion(y_pred.squeeze(), y_seq_letter.squeeze())\n",
        "            if torch.argmax(y_seq_letter)==torch.argmax(y_pred):\n",
        "                Accuracy+=1\n",
        "\n",
        "        print('Accuracy',Accuracy/(50*i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Задание 2.\n",
        "\n",
        "Выполнить практическую работу из лекционного ноутбука.\n",
        "\n",
        "* Построить RNN-ячейку на основе полносвязных слоев\n",
        "* Применить построенную ячейку для генерации текста с выражениями героев сериала “Симпсоны”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10891 entries, 0 to 10890\n",
            "Data columns (total 1 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   normalized_text  10891 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 85.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('data.csv',usecols=['normalized_text'])\n",
        "\n",
        "df=df.dropna().reset_index(drop=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "id": "fdnPKfK8oMAL",
        "outputId": "11298ddb-b1c2-4de8-a462-da394ba8552d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['maggie look whats that', 'lee-mur lee-mur', 'zee-boo zee-boo']"
            ]
          },
          "execution_count": 312,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phrases = df['normalized_text'].tolist()  # колонка с предобработанными текстами\n",
        "phrases[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "id": "fL50SHMOoMAM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10891"
            ]
          },
          "execution_count": 313,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = [[c for c in ph] for ph in phrases[:] if type(ph) is str]\n",
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "id": "9rpbhYWqoMAa"
      },
      "outputs": [],
      "source": [
        "CHARS = set('abcdefghijklmnopqrstuvwxyz ')  # все символы, которые мы хотим использовать для кодировки = наш словарь\n",
        "INDEX_TO_CHAR = ['none'] + [w for w in CHARS]  # все неизвестные символы будут получать тег none\n",
        "CHAR_TO_INDEX = {w: i for i, w in enumerate(INDEX_TO_CHAR)}  # словарь токен-индекс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 315,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(INDEX_TO_CHAR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "uH0TI94doMAb"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 50  # мы хотим ограничить максимальную длину ввода\n",
        "X = torch.zeros((len(text), MAX_LEN), dtype=int)  # создаём пустой вектор для текста, чтобы класть в него индексы токенов\n",
        "for i in range(len(text)):  # для каждого предложения\n",
        "    for j, w in enumerate(text[i]):  # для каждого токена\n",
        "        if j >= MAX_LEN:\n",
        "            break\n",
        "        X[i, j] = CHAR_TO_INDEX.get(w, CHAR_TO_INDEX['none'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[20, 25,  9,  9, 10, 24, 23, 14,  4,  4, 22, 23, 27, 16, 25, 11,  7, 23,\n",
              "         11, 16, 25, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [14, 24, 24,  0, 20,  8,  3, 23, 14, 24, 24,  0, 20,  8,  3,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [13, 24, 24,  0,  1,  4,  4, 23, 13, 24, 24,  0,  1,  4,  4,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "execution_count": 303,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.8562,  0.6740, -0.1146, -1.3983, -0.6542,  0.6780,  1.8432, -0.1798,\n",
              "        -0.8857, -0.7985, -0.6601,  0.1404,  1.3827, -0.3618, -0.0317, -0.3046,\n",
              "        -0.6910,  0.4317, -0.2950, -0.6300,  0.6399,  0.4062, -1.9184, -0.7232,\n",
              "         0.5824,  1.0812,  0.1840, -0.7603], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 317,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings = torch.nn.Embedding(len(INDEX_TO_CHAR), 28)  # размер словаря * размер вектора для кодировки каждого слова\n",
        "t = embeddings(X[0:5])\n",
        "t[0][0].shape\n",
        "t[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5, 50, 28]), torch.Size([5, 50]))"
            ]
          },
          "execution_count": 318,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t.shape, X[0:5].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5, 50, 128]), torch.Size([1, 5, 128]))"
            ]
          },
          "execution_count": 319,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnn = torch.nn.RNN(28, 128, batch_first=True)  # на вход - размер эмбеддинга, размер скрытого состояния и порядок размерностей\n",
        "o, s = rnn(t)\n",
        "# вектора для слов: батч * число токенов * размер скрытого состояния\n",
        "# вектор скрытого состояния: число вектров (один) * батч * размер скрытого состояния\n",
        "o.shape, s.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "        self.embedding = torch.nn.Embedding(28, 28)\n",
        "        self.rnn = torch.nn.RNN(28, 128)\n",
        "        self.out = torch.nn.Linear(128, 28)\n",
        "\n",
        "    def forward(self, sentences, state=None):\n",
        "        x = self.embedding(sentences)\n",
        "        x, s = self.rnn(x) # берём выход с последнего слоя для всех токенов, а не скрытое состояние\n",
        "        return self.out(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Network()\n",
        "criterion = torch.nn.CrossEntropyLoss()  # типичный лосс многоклассовой классификации\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0. Time: 10.038, Train loss: 1.816\n",
            "Epoch 1. Time: 10.413, Train loss: 1.777\n",
            "Epoch 2. Time: 9.035, Train loss: 1.751\n",
            "Epoch 3. Time: 9.919, Train loss: 1.732\n",
            "Epoch 4. Time: 9.863, Train loss: 1.718\n",
            "Epoch 5. Time: 9.485, Train loss: 1.707\n",
            "Epoch 6. Time: 8.612, Train loss: 1.699\n",
            "Epoch 7. Time: 8.818, Train loss: 1.692\n",
            "Epoch 8. Time: 9.048, Train loss: 1.686\n",
            "Epoch 9. Time: 11.860, Train loss: 1.682\n",
            "Epoch 10. Time: 10.819, Train loss: 1.678\n",
            "Epoch 11. Time: 10.929, Train loss: 1.674\n",
            "Epoch 12. Time: 10.765, Train loss: 1.672\n",
            "Epoch 13. Time: 10.401, Train loss: 1.669\n",
            "Epoch 14. Time: 9.088, Train loss: 1.667\n",
            "Epoch 15. Time: 8.879, Train loss: 1.665\n",
            "Epoch 16. Time: 8.803, Train loss: 1.663\n",
            "Epoch 17. Time: 8.939, Train loss: 1.661\n",
            "Epoch 18. Time: 9.244, Train loss: 1.660\n",
            "Epoch 19. Time: 8.959, Train loss: 1.658\n"
          ]
        }
      ],
      "source": [
        "for ep in range(20):\n",
        "    start = time.time()\n",
        "    train_loss = 0.\n",
        "    train_passed = 0\n",
        "\n",
        "    for i in range(int(len(X) / 100)):\n",
        "        # берём батч в 100 элементов\n",
        "        batch = X[i * 100:(i + 1) * 100]\n",
        "        X_batch = batch[:, :-1]\n",
        "        Y_batch = batch[:, 1:].flatten()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        answers = model.forward(X_batch)\n",
        "        answers = answers.view(-1, len(INDEX_TO_CHAR))\n",
        "        loss = criterion(answers, Y_batch)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_passed += 1\n",
        "\n",
        "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss/train_passed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHAR_TO_INDEX['none']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_sentence(word):\n",
        "    sentence = list(word)\n",
        "    sentence = [CHAR_TO_INDEX.get(s, 0) for s in sentence]\n",
        "    answers = model.forward(torch.tensor(sentence))\n",
        "    probas, indices = answers.topk(1)\n",
        "    return ''.join([INDEX_TO_CHAR[ind.item()] for ind in indices.flatten()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'aue'"
            ]
          },
          "execution_count": 325,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_sentence('mom')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " w\n",
            " wwe\n",
            " wweweh \n",
            " wweweh weh h et\n",
            " wweweh weh h etweh h ete etet  \n",
            " wweweh weh h etweh h ete etet  weh h ete etet  e etet   t    tt\n"
          ]
        }
      ],
      "source": [
        "s='look maggie what is that dodecahedron'.split(' ')\n",
        "x1=' '\n",
        "for x in s:\n",
        "    x1+=generate_sentence(x1)\n",
        "    print(x1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

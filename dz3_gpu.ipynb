{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WGoorsK6mPZP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WIcNCt4ZmPZZ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yiHPlx2wmPZe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torchvision as tv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Kw5Kv2i6mPZu"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=256\n",
        "\n",
        "transforms = tv.transforms.Compose([\n",
        "    tv.transforms.Resize(32),\n",
        "    tv.transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=transforms, download=True)\n",
        "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=transforms, download=True)\n",
        "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKhbDXt_mPZ0",
        "outputId": "2b1be7fa-05d9-462a-b054-45634e37ae3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\n",
        "train_dataset[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "V7qWC2EbmPZ5"
      },
      "outputs": [],
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Conv2d(1, 6, kernel_size=5, padding=0),\n",
        "    torch.nn.Tanh(),\n",
        "    torch.nn.AvgPool2d(2, stride=2),\n",
        "    torch.nn.Conv2d(6, 16, kernel_size=5),\n",
        "    torch.nn.Tanh(),\n",
        "    torch.nn.AvgPool2d(2, stride=2),\n",
        "    torch.nn.Conv2d(16, 120, kernel_size=5),\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(120, 84),\n",
        "    torch.nn.Tanh(),\n",
        "    torch.nn.Dropout(0.1),\n",
        "    torch.nn.Linear(84, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PxMXK2w78LWm",
        "outputId": "b0a2dc5f-5a24-4f25-bdd2-1d60af4c8b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model = torch.nn.Sequential(\\n    torch.nn.Flatten(),\\n    torch.nn.Linear(784, 1024),\\n    torch.nn.BatchNorm1d(1024),\\n    torch.nn.ReLU(),\\n    torch.nn.Dropout(0.1),\\n    torch.nn.Linear(1024, 512),\\n    torch.nn.BatchNorm1d(512),\\n    torch.nn.ReLU(),\\n    torch.nn.Dropout(0.2),\\n    torch.nn.Linear(512, 256),\\n    torch.nn.BatchNorm1d(256),\\n    torch.nn.ReLU(),\\n    torch.nn.Dropout(0.3),\\n    torch.nn.Linear(256, 10)\\n)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "'''model = torch.nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.Linear(784, 1024),\n",
        "    torch.nn.BatchNorm1d(1024),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(0.1),\n",
        "    torch.nn.Linear(1024, 512),\n",
        "    torch.nn.BatchNorm1d(512),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(0.2),\n",
        "    torch.nn.Linear(512, 256),\n",
        "    torch.nn.BatchNorm1d(256),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Dropout(0.3),\n",
        "    torch.nn.Linear(256, 10)\n",
        ")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p36P60xZALtj",
        "outputId": "9eb9a76b-1889-4f32-d30e-28b20c0ff913"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (1): Tanh()\n",
              "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (4): Tanh()\n",
              "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (7): Flatten(start_dim=1, end_dim=-1)\n",
              "  (8): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (9): Tanh()\n",
              "  (10): Dropout(p=0.1, inplace=False)\n",
              "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fDqkL214mPZ7"
      },
      "outputs": [],
      "source": [
        "loss = torch.nn.CrossEntropyLoss()\n",
        "trainer = torch.optim.Adam(model.parameters(), lr=.001)\n",
        "num_epochs = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Y1wiYTOO8LWn"
      },
      "outputs": [],
      "source": [
        "#from prettytable import PrettyTable\n",
        "#x = PrettyTable()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "kWD8iLrF9oYg",
        "outputId": "f92cd864-d8e1-4bc2-8476-98656d3761aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "-mldqpH79pTz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vVqz1hvTmPaA"
      },
      "outputs": [],
      "source": [
        "#x.field_names = [\"EPOCH\", \"TimeTaked\", \"train_loss\", \"train_acc\", \"test_loss\", \"test_acc\"]\n",
        "def train_model(device):\n",
        "    for ep in range(num_epochs):\n",
        "        train_iters, train_passed = 0, 0\n",
        "        train_loss, train_acc = 0., 0.\n",
        "        start = time.time()\n",
        "\n",
        "        model.train()\n",
        "        for X, y in train:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            trainer.zero_grad()\n",
        "            y_pred = model(X)\n",
        "            l = loss(y_pred, y)\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_loss += l.item()\n",
        "            train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
        "            train_iters += 1\n",
        "            train_passed += len(X)\n",
        "\n",
        "        test_iters, test_passed = 0, 0\n",
        "        test_loss, test_acc = 0., 0.\n",
        "        model.eval()\n",
        "        for X, y in test:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_pred = model(X)\n",
        "            l = loss(y_pred, y)\n",
        "            test_loss += l.item()\n",
        "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
        "            test_iters += 1\n",
        "            test_passed += len(X)\n",
        "        count_ep = ep+1\n",
        "        if count_ep % 15 == 0:\n",
        "            print(\"epoch: {}, taked_time: {:.3f}, train_loss: {:.3f}, train_acc: {:.3f}, test_loss: {:.3f}, test_acc: {:.3f}\".format(\n",
        "                count_ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
        "                test_loss / test_iters, test_acc / test_passed)\n",
        "            )\n",
        "        #x.add_row([round(ep,3),round(time.time() - start,3), round(train_loss / train_iters,3), round(train_acc / train_passed,3), round(test_loss / test_iters,3), round(test_acc / test_passed,3)])\n",
        "        # print(x.get_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbXgnTAKPyi2",
        "outputId": "c966a366-4fd0-4f83-fd92-98fcb25949b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 15, taked_time: 11.330, train_loss: 0.314, train_acc: 0.884, test_loss: 0.339, test_acc: 0.875\n",
            "epoch: 30, taked_time: 11.566, train_loss: 0.262, train_acc: 0.904, test_loss: 0.314, test_acc: 0.886\n",
            "epoch: 45, taked_time: 11.517, train_loss: 0.235, train_acc: 0.912, test_loss: 0.309, test_acc: 0.888\n",
            "epoch: 60, taked_time: 11.503, train_loss: 0.214, train_acc: 0.920, test_loss: 0.302, test_acc: 0.891\n",
            "epoch: 75, taked_time: 11.565, train_loss: 0.198, train_acc: 0.927, test_loss: 0.305, test_acc: 0.890\n",
            "epoch: 90, taked_time: 11.637, train_loss: 0.186, train_acc: 0.931, test_loss: 0.315, test_acc: 0.893\n",
            "epoch: 105, taked_time: 11.703, train_loss: 0.175, train_acc: 0.935, test_loss: 0.313, test_acc: 0.895\n",
            "epoch: 120, taked_time: 11.509, train_loss: 0.166, train_acc: 0.938, test_loss: 0.313, test_acc: 0.894\n",
            "epoch: 135, taked_time: 11.502, train_loss: 0.159, train_acc: 0.940, test_loss: 0.329, test_acc: 0.892\n",
            "epoch: 150, taked_time: 11.389, train_loss: 0.152, train_acc: 0.943, test_loss: 0.334, test_acc: 0.895\n"
          ]
        }
      ],
      "source": [
        "train_model(device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
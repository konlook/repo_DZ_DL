{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW_IMrzboL_v"
      },
      "source": [
        "Задание 1. \n",
        "\n",
        "Сгенерируйте последовательности цифр от 0 до 9, \n",
        "которые бы задавались следующим\n",
        "образом:\n",
        "\n",
        "● x - последовательность цифр\n",
        "\n",
        "● y1 = x1, y(i) = x(i) + x(1). Если y(i) >= 10, то y(i) = y(i) - 10\n",
        "\n",
        "1. Научите модель предсказывать y(i) по x(i)\n",
        "2. Попробуйте RNN, LSTM, GRU\n",
        "Задание 2* (дополнительное и необязательное)\n",
        "Примените LSTM для решения лекционного практического задания\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "gYu83KWCoL_3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # для работы с данными\n",
        "import time  # для оценки времени\n",
        "import torch  # для написания нейросети\n",
        "import numpy as np\n",
        "import re\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[6, 5, 7,  ..., 1, 5, 8],\n",
              "         [4, 2, 0,  ..., 4, 0, 2],\n",
              "         [3, 0, 1,  ..., 7, 7, 7],\n",
              "         ...,\n",
              "         [7, 6, 8,  ..., 8, 6, 4],\n",
              "         [7, 8, 7,  ..., 5, 8, 7],\n",
              "         [1, 4, 2,  ..., 1, 0, 0]],\n",
              "\n",
              "        [[8, 8, 2,  ..., 2, 8, 1],\n",
              "         [7, 4, 0,  ..., 4, 1, 1],\n",
              "         [3, 3, 8,  ..., 3, 5, 4],\n",
              "         ...,\n",
              "         [1, 5, 8,  ..., 2, 7, 6],\n",
              "         [6, 7, 2,  ..., 1, 4, 1],\n",
              "         [4, 0, 5,  ..., 3, 2, 1]]])"
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "ds_digit_25 = torch.randint(0, 9, (2,1000,25))\n",
        "ds_digit_75 = torch.randint(0, 9, (2,1000,75))\n",
        "ds_digit_150 = torch.randint(0, 9, (2,1000,150))\n",
        "ds_digit_25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[6, 5, 7,  ..., 1, 5, 8],\n",
              "        [4, 2, 0,  ..., 4, 0, 2],\n",
              "        [3, 0, 1,  ..., 7, 7, 7],\n",
              "        ...,\n",
              "        [7, 6, 8,  ..., 8, 6, 4],\n",
              "        [7, 8, 7,  ..., 5, 8, 7],\n",
              "        [1, 4, 2,  ..., 1, 0, 0]])"
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_digit_25[0,:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "execution_count": 228,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vec_digit=torch.eye(10,10)\n",
        "vec_digit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "FlNxD3M6oL_4"
      },
      "outputs": [],
      "source": [
        "def f_cifer_cesar(dig_set):\n",
        "\n",
        "    #dig_set[:][0][:] == X\n",
        "    #dig_set[:][1][:] == Y\n",
        "\n",
        "    for i in range(dig_set.shape[1]):\n",
        "        for j in range(dig_set.shape[2]):\n",
        "            if j==0:\n",
        "                dig_set[1,i,j]=dig_set[0,i,j]\n",
        "            else:\n",
        "                dig_set[1,i,j]=dig_set[0,i,j]+dig_set[0,i,0]\n",
        "                if dig_set[1,i,j]>9:\n",
        "                    dig_set[1,i,j]=dig_set[1,i,j]-10\n",
        "    return dig_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([6, 5, 7, 4, 0, 2, 7, 5, 4, 2, 4, 4, 8, 0, 0, 4, 2, 4, 3, 4, 4, 8, 1, 5,\n",
              "         8]),\n",
              " tensor([6, 1, 3, 0, 6, 8, 3, 1, 0, 8, 0, 0, 4, 6, 6, 0, 8, 0, 9, 0, 0, 4, 7, 1,\n",
              "         4]))"
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_digit_25 = f_cifer_cesar(ds_digit_25)\n",
        "ds_digit_75 = f_cifer_cesar(ds_digit_75)\n",
        "ds_digit_150 = f_cifer_cesar(ds_digit_150)\n",
        "ds_digit_25[0,0,:],ds_digit_25[1,0,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1000, 25])"
            ]
          },
          "execution_count": 231,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_digit_25[0,:,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "Wo3OHLQ3oMAG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import  train_test_split\n",
        "X_train_25, X_test_25, y_train_25, y_test_25 = train_test_split(ds_digit_25[0,:,:], ds_digit_25[1,:,:], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_75, X_test_75, y_train_75, y_test_75 = train_test_split(ds_digit_75[0,:,:], ds_digit_75[1,:,:], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_150, X_test_150, y_train_150, y_test_150 = train_test_split(ds_digit_150[0,:,:], ds_digit_150[1,:,:], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(800, 200)"
            ]
          },
          "execution_count": 235,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_train_25),len(y_test_25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def input_data(seq_x, seq_y):\n",
        "    out = []\n",
        "    L = seq_x.shape[0]\n",
        "    \n",
        "    for i in range(L):\n",
        "        x = seq_x[i,:]\n",
        "        y = seq_y[i,:]\n",
        "        out.append((x,y))\n",
        "    \n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_data_25 = input_data(X_train_25,y_train_25)\n",
        "test_data_25 = input_data(X_test_25,y_test_25)\n",
        "\n",
        "train_data_75 = input_data(X_train_75,y_train_75)\n",
        "test_data_75 = input_data(X_test_75,y_test_75)\n",
        "\n",
        "train_data_150 = input_data(X_train_150,y_train_150)\n",
        "test_data_150 = input_data(X_test_150,y_test_150)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "Wwlt7K16vavV"
      },
      "outputs": [],
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [],
      "source": [
        "class myGRU(torch.nn.Module):\n",
        "    def __init__(self, rnnClass=torch.nn.GRU, dictionary_size=None, embedding_size=10, num_hiddens=128, num_classes=10):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.num_hiddens = num_hiddens\n",
        "        #self.embedding = torch.nn.Embedding(dictionary_size, embedding_size)\n",
        "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
        "        self.output = torch.nn.Linear(num_hiddens, num_classes)\n",
        "        \n",
        "    def forward(self, seq):\n",
        "        #out = self.embedding(X)\n",
        "        _, state = self.hidden(seq.view(1,1,10))\n",
        "        predictions = self.output(state[0].squeeze())\n",
        "        return predictions\n",
        "    \n",
        "#model = NeuralNetwork(torch.nn.GRU, len(CHAR_TO_INDEX), 64, 128, len(CHAR_TO_INDEX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [],
      "source": [
        "class myRNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        #self.embedding = torch.nn.Embedding(28, 30)\n",
        "        self.rnn = torch.nn.RNN(10, 128)\n",
        "        self.out = torch.nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, seq, state=None):\n",
        "        #x = self.embedding(sentences)\n",
        "        x, s = self.rnn(seq.view(1,1,10)) # берём выход с последнего слоя для всех токенов, а не скрытое состояние\n",
        "        return self.out(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [],
      "source": [
        "class myLSTM(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self,input_size = 10, hidden_size = 128, out_size = 10):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size)\n",
        "        self.linear = torch.nn.Linear(hidden_size,out_size)\n",
        "        self.hidden = (torch.zeros(1,1,hidden_size),torch.zeros(1,1,hidden_size))\n",
        "    \n",
        "    def forward(self,seq):\n",
        "        #lstm_out, self.hidden = self.lstm(seq.view(len(seq),1,-1), self.hidden)\n",
        "        lstm_out, self.hidden = self.lstm(seq.view(1,1,10), self.hidden)\n",
        "        pred = self.linear(lstm_out.view(128))\n",
        "        return pred#[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "__main__.myGRU"
            ]
          },
          "execution_count": 249,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = myGRU()\n",
        "(type(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_my_models(locmodel,train_data,test_data,epochs = 3):\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    \n",
        "    criterion = torch.nn.MSELoss()#reduction='sum'\n",
        "    optimizer = torch.optim.Adam(locmodel.parameters(), lr=0.001)\n",
        "    scheduler1 = lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0.00001)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        \n",
        "        for x_seq, y_seq in train_data[:80][:]:\n",
        "            for x_seq_letter, y_seq_letter in zip(x_seq, y_seq):\n",
        "                \n",
        "                x_seq_letter=vectors_letter[x_seq_letter]\n",
        "                y_seq_letter=vectors_letter[y_seq_letter]\n",
        "                #print(x_seq_letter,'\\n',y_seq_letter,'\\n')\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                if type(locmodel) == myLSTM:\n",
        "                    locmodel.hidden = (torch.zeros(1,1,locmodel.hidden_size),torch.zeros(1,1,locmodel.hidden_size))\n",
        "                \n",
        "                y_pred = locmodel(x_seq_letter)\n",
        "                loss = criterion(y_pred.squeeze(), y_seq_letter)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "        \n",
        "        scheduler1.step()\n",
        "        \n",
        "        for x_seq, y_seq in test_data[:20][:]:  \n",
        "            for x_seq_letter, y_seq_letter in zip(x_seq, y_seq):  \n",
        "\n",
        "                x_seq_letter=vectors_letter[x_seq_letter]\n",
        "                y_seq_letter=vectors_letter[y_seq_letter]\n",
        "\n",
        "                y_pred = locmodel(x_seq_letter.squeeze())\n",
        "                \n",
        "                loss_test = criterion(y_pred.squeeze(), y_seq_letter.squeeze())\n",
        "                \n",
        "        if (i+1) % 1 == 0:\n",
        "            print(f\"Epoch {i+1} MSE_TRAIN_Loss: {loss.item()}\")\n",
        "            print(f\"          MSE_TEST__Loss: {loss_test}\")\n",
        "\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 MSE_TRAIN_Loss: 0.09926282614469528\n",
            "          MSE_TEST__Loss: 0.08214692771434784\n",
            "Epoch 2 MSE_TRAIN_Loss: 0.09724553674459457\n",
            "          MSE_TEST__Loss: 0.08198340237140656\n",
            "Epoch 3 MSE_TRAIN_Loss: 0.09880097955465317\n",
            "          MSE_TEST__Loss: 0.08440891653299332\n",
            "Epoch 1 MSE_TRAIN_Loss: 0.04933413118124008\n",
            "          MSE_TEST__Loss: 0.08907286822795868\n",
            "Epoch 2 MSE_TRAIN_Loss: 0.053418297320604324\n",
            "          MSE_TEST__Loss: 0.08606407046318054\n",
            "Epoch 3 MSE_TRAIN_Loss: 0.062094878405332565\n",
            "          MSE_TEST__Loss: 0.07785577327013016\n",
            "Epoch 1 MSE_TRAIN_Loss: 0.01772923208773136\n",
            "          MSE_TEST__Loss: 0.1257902830839157\n",
            "Epoch 2 MSE_TRAIN_Loss: 0.02250424027442932\n",
            "          MSE_TEST__Loss: 0.11995366960763931\n",
            "Epoch 3 MSE_TRAIN_Loss: 0.03684030845761299\n",
            "          MSE_TEST__Loss: 0.10945238173007965\n",
            "Epoch 1 MSE_TRAIN_Loss: 0.10180799663066864\n",
            "          MSE_TEST__Loss: 0.0846046656370163\n",
            "Epoch 2 MSE_TRAIN_Loss: 0.10100273042917252\n",
            "          MSE_TEST__Loss: 0.08549565821886063\n",
            "Epoch 3 MSE_TRAIN_Loss: 0.10130806267261505\n",
            "          MSE_TEST__Loss: 0.08747907727956772\n",
            "Epoch 1 MSE_TRAIN_Loss: 0.06546209752559662\n",
            "          MSE_TEST__Loss: 0.07852883636951447\n",
            "Epoch 2 MSE_TRAIN_Loss: 0.06631776690483093\n",
            "          MSE_TEST__Loss: 0.07560475170612335\n",
            "Epoch 3 MSE_TRAIN_Loss: 0.07204067707061768\n",
            "          MSE_TEST__Loss: 0.07791842520236969\n",
            "Epoch 1 MSE_TRAIN_Loss: 0.043315380811691284\n",
            "          MSE_TEST__Loss: 0.10660507529973984\n",
            "Epoch 2 MSE_TRAIN_Loss: 0.04589336737990379\n",
            "          MSE_TEST__Loss: 0.0949091762304306\n",
            "Epoch 3 MSE_TRAIN_Loss: 0.05398029088973999\n",
            "          MSE_TEST__Loss: 0.08762752264738083\n",
            "Epoch 1 MSE_TRAIN_Loss: 0.10235387086868286\n",
            "          MSE_TEST__Loss: 0.07255600392818451\n",
            "Epoch 2 MSE_TRAIN_Loss: 0.10189646482467651\n",
            "          MSE_TEST__Loss: 0.07426761835813522\n",
            "Epoch 3 MSE_TRAIN_Loss: 0.10106168687343597\n",
            "          MSE_TEST__Loss: 0.07611812651157379\n",
            "Epoch 1 MSE_TRAIN_Loss: 0.06973717361688614\n",
            "          MSE_TEST__Loss: 0.0787242203950882\n",
            "Epoch 2 MSE_TRAIN_Loss: 0.07052494585514069\n",
            "          MSE_TEST__Loss: 0.08013857156038284\n",
            "Epoch 3 MSE_TRAIN_Loss: 0.07363753020763397\n",
            "          MSE_TEST__Loss: 0.08015941083431244\n",
            "Epoch 1 MSE_TRAIN_Loss: 0.04547521844506264\n",
            "          MSE_TEST__Loss: 0.11274025589227676\n",
            "Epoch 2 MSE_TRAIN_Loss: 0.04842066764831543\n",
            "          MSE_TEST__Loss: 0.09764198958873749\n",
            "Epoch 3 MSE_TRAIN_Loss: 0.05414005368947983\n",
            "          MSE_TEST__Loss: 0.09337205439805984\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 251,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_my_models(myRNN(),train_data_25,test_data_25)\n",
        "train_my_models(myRNN(),train_data_75,test_data_75)\n",
        "train_my_models(myRNN(),train_data_150,test_data_150)\n",
        "\n",
        "train_my_models(myGRU(),train_data_25,test_data_25)\n",
        "train_my_models(myGRU(),train_data_75,test_data_75)\n",
        "train_my_models(myGRU(),train_data_150,test_data_150)\n",
        "\n",
        "train_my_models(myLSTM(),train_data_25,test_data_25)\n",
        "train_my_models(myLSTM(),train_data_75,test_data_75)\n",
        "train_my_models(myLSTM(),train_data_150,test_data_150)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validation_mymodel(locmodel,test_data):\n",
        "     i=0\n",
        "     Accuracy=0\n",
        "     \n",
        "     if type(locmodel)==myRNN:\n",
        "         model_name='myRNN'\n",
        "     elif type(locmodel)==myGRU:\n",
        "         model_name='myGRU'\n",
        "     elif type(locmodel) == myLSTM:\n",
        "         model_name='myLSTM'\n",
        "\n",
        "\n",
        "     if test_data[:1][0][0].shape[0]==25:\n",
        "          dataset_name='series_25'\n",
        "     elif test_data[:1][0][0].shape[0]==75:\n",
        "          dataset_name='series_75'\n",
        "     elif test_data[:1][0][0].shape[0]==150:\n",
        "          dataset_name='series_150'\n",
        "             \n",
        "     for x_seq, y_seq in test_data[:200][:]:  \n",
        "            \n",
        "            i+=1\n",
        "            for x_seq_letter, y_seq_letter in zip(x_seq, y_seq):  \n",
        "\n",
        "                x_seq_letter=vectors_letter[x_seq_letter]\n",
        "                y_seq_letter=vectors_letter[y_seq_letter]\n",
        "\n",
        "                y_pred = locmodel(x_seq_letter.squeeze())\n",
        "                \n",
        "                #loss_test = criterion(y_pred.squeeze(), y_seq_letter.squeeze())\n",
        "                if torch.argmax(y_seq_letter)==torch.argmax(y_pred):\n",
        "                    Accuracy+=1\n",
        "                    \n",
        "     print(f'Accuracy for {model_name} and {dataset_name}',Accuracy/(25*i))\n",
        "     return Accuracy/(25*i)#model_name,dataset_name,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for myRNN and series_25 0.1112\n",
            "Accuracy for myRNN and series_75 0.3314\n",
            "Accuracy for myRNN and series_150 0.5924\n",
            "Accuracy for myGRU and series_25 0.0924\n",
            "Accuracy for myGRU and series_75 0.2742\n",
            "Accuracy for myGRU and series_150 0.559\n",
            "Accuracy for myLSTM and series_25 0.1072\n",
            "Accuracy for myLSTM and series_75 0.3058\n",
            "Accuracy for myLSTM and series_150 0.6056\n"
          ]
        }
      ],
      "source": [
        "r,g,l=[],[],[]\n",
        "\n",
        "r.append(validation_mymodel(myRNN(),test_data_25))\n",
        "r.append(validation_mymodel(myRNN(),test_data_75))\n",
        "r.append(validation_mymodel(myRNN(),test_data_150))\n",
        "\n",
        "g.append(validation_mymodel(myGRU(),test_data_25))\n",
        "g.append(validation_mymodel(myGRU(),test_data_75))\n",
        "g.append(validation_mymodel(myGRU(),test_data_150))\n",
        "\n",
        "l.append(validation_mymodel(myLSTM(),test_data_25))\n",
        "l.append(validation_mymodel(myLSTM(),test_data_75))\n",
        "l.append(validation_mymodel(myLSTM(),test_data_150))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------+--------+--------+--------+\n",
            "| LenghtOfSeries |  RNN   |  GRU   |  LSTM  |\n",
            "+----------------+--------+--------+--------+\n",
            "|   series_25    | 0.1112 | 0.0924 | 0.1072 |\n",
            "|   series_75    | 0.3314 | 0.2742 | 0.3058 |\n",
            "|   series_150   | 0.5924 | 0.559  | 0.6056 |\n",
            "+----------------+--------+--------+--------+\n"
          ]
        }
      ],
      "source": [
        "from prettytable import PrettyTable\n",
        "x = PrettyTable()\n",
        "\n",
        "x.field_names = ['LenghtOfSeries',\"RNN\", \"GRU\", \"LSTM\"]\n",
        "x.add_row(['series_25 ',r[0], g[0], l[0] ])\n",
        "x.add_row(['series_75 ',r[1], g[1], l[1]])\n",
        "x.add_row(['series_150',r[2], g[2], l[2]])\n",
        "\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Задание 2:\n",
        "применить LSTM для решения лекционного практического задания"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import re\n",
        "import random\n",
        "import tqdm\n",
        "import time\n",
        "\n",
        "# !wget https://s3.amazonaws.com/text-datasets/nietzsche.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length: 600893\n"
          ]
        }
      ],
      "source": [
        "with open('nietzsche.txt', encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('length:', len(text))\n",
        "text = re.sub('[^a-z ]', ' ', text)\n",
        "text = re.sub('\\s+', ' ', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "INDEX_TO_CHAR = sorted(list(set(text)))\n",
        "CHAR_TO_INDEX = {c: i for i, c in enumerate(INDEX_TO_CHAR)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num sents: 193075\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 40\n",
        "STEP = 3\n",
        "SENTENCES = []\n",
        "NEXT_CHARS = []\n",
        "for i in range(0, len(text) - MAX_LEN, STEP):\n",
        "    SENTENCES.append(text[i: i + MAX_LEN])\n",
        "    NEXT_CHARS.append(text[i + MAX_LEN])\n",
        "print('Num sents:', len(SENTENCES))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ]
        }
      ],
      "source": [
        "print('Vectorization...')\n",
        "X = torch.zeros((len(SENTENCES), MAX_LEN), dtype=int)\n",
        "Y = torch.zeros((len(SENTENCES)), dtype=int)\n",
        "for i, sentence in enumerate(SENTENCES):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t] = CHAR_TO_INDEX[char]\n",
        "    Y[i] = CHAR_TO_INDEX[NEXT_CHARS[i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE=40\n",
        "dataset = torch.utils.data.TensorDataset(X[:-35], Y[:-35])\n",
        "data = torch.utils.data.DataLoader(dataset, BATCH_SIZE, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, rnnClass, dictionary_size, embedding_size, num_hiddens, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.embedding = nn.Embedding(dictionary_size, embedding_size)\n",
        "        self.hidden = rnnClass(embedding_size, num_hiddens, batch_first=True)\n",
        "        self.output = nn.Linear(num_hiddens, num_classes)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        out = self.embedding(X.squeeze())\n",
        "        out, state = self.hidden(out)\n",
        "        predictions = self.output(out[0].squeeze())\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = NeuralNetwork(nn.LSTM, len(CHAR_TO_INDEX), 64, 128, len(CHAR_TO_INDEX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample(preds):\n",
        "    softmaxed = torch.softmax(preds, 0)\n",
        "    probas = torch.distributions.multinomial.Multinomial(1, softmaxed).sample()\n",
        "    return probas.argmax()\n",
        "\n",
        "def generate_text():\n",
        "    start_index = random.randint(0, len(text) - MAX_LEN - 1)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + MAX_LEN]\n",
        "    generated += sentence\n",
        "\n",
        "    for i in range(MAX_LEN):\n",
        "        x_pred = torch.zeros((1, MAX_LEN), dtype=int)\n",
        "        for t, char in enumerate(generated[-MAX_LEN:]):\n",
        "            x_pred[0, t] = CHAR_TO_INDEX[char]\n",
        "\n",
        "        preds = model(x_pred)#[0] #model(x_pred.cuda())[0].cpu()\n",
        "        next_char = INDEX_TO_CHAR[sample(preds)]\n",
        "        generated = generated + next_char\n",
        "\n",
        "    print(generated[:MAX_LEN] + '|' + generated[MAX_LEN:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "old it addresses itself to men free from|frroo slvt  rnt asrceshsur h nshduetsdag\n"
          ]
        }
      ],
      "source": [
        "generate_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0. Time: 257.145, Train loss: 2.845\n",
            " ensues accompanied by a desire for some|e tmii otpn tm rpdtnec to ottnet ibeeect\n",
            "Epoch 1. Time: 268.921, Train loss: 2.839\n",
            "ism in europe let us not be ungrateful t|stert i  t nghiaennki  pod sasw   ofte l\n"
          ]
        }
      ],
      "source": [
        "for ep in range(2):\n",
        "    start = time.time()\n",
        "    train_loss = 0.\n",
        "    train_passed = 0\n",
        "\n",
        "    model.train()\n",
        "    for X_b, y_b in data:\n",
        "        #X_b, y_b = X_b, y_b#X_b, y_b = X_b.cuda(), y_b.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        answers = model(X_b.squeeze())\n",
        "        loss = criterion(answers.squeeze(), y_b.squeeze())\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_passed += 1\n",
        "\n",
        "    print(\"Epoch {}. Time: {:.3f}, Train loss: {:.3f}\".format(ep, time.time() - start, train_loss / train_passed))\n",
        "    model.eval()\n",
        "    generate_text()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
